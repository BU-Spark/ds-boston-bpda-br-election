{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920f8202",
   "metadata": {},
   "source": [
    "# CSV Clean\n",
    "This Notebook contains functions to clean the electorate and election datasets and write the new files into CSVs in a clean_data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8e5c48",
   "metadata": {},
   "source": [
    "## Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "071afc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_cleaning.country_match import country_code_map as geomap\n",
    "from data_cleaning import cleaning_utilities\n",
    "from data_cleaning.education_codes import add_education_codes\n",
    "from data_cleaning.education_codes import clean2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b376f0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Dataframes and clean countries/education codes\n",
    "def extract_dataframe(path: str, remove_extra_header=False):\n",
    "    '''\n",
    "    Creates a Pandas Data Frame from a CSV File and makes headers uniform (lower cases, separated by _ vs space)\n",
    "    :param path - A path to a CSV File\n",
    "    :param remove_extra_header - A boolean to indicate if there is an extra header (Portuguese) which can be removed\n",
    "    :return a Pandas dataframe\n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    if remove_extra_header:\n",
    "        df = pd.read_csv(path, skiprows=[1])\n",
    "        new_column_names = [x.lower().replace(' ','_') for x in df.columns]\n",
    "        df.columns = new_column_names\n",
    "        \n",
    "    else:\n",
    "        df = pd.read_csv(path)\n",
    "        new_column_names = [x.lower().replace(' ','_') for x in df.columns]\n",
    "        df.columns = new_column_names\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f897c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_country_name(df):\n",
    "    '''\n",
    "    Standardizes Country Name (by removing accents)\n",
    "    :param path - A pandas dataframe\n",
    "    :return The updated pandas dataframe (with accents removed)\n",
    "    '''\n",
    "    #Remove accents from country names\n",
    "    countries = df['municipality_name'].tolist()\n",
    "    countries = [cleaning_utilities.remove_accents(country) for country in countries]\n",
    "    df['municipality_name'] = countries\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_edu_attainment(df):\n",
    "    '''\n",
    "    Standardizes Educational Attainment Description (by removing accents)\n",
    "    :param path - A pandas dataframe\n",
    "    :return The updated pandas dataframe (with accents removed)\n",
    "    '''\n",
    "    #Remove accents from educational attainment description\n",
    "    education_levels = df[\"educational_attainment_description\"].tolist()\n",
    "    education_levels = [cleaning_utilities.remove_accents(edu_desc) for edu_desc in education_levels]\n",
    "    df[\"educational_attainment_description\"] = education_levels\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0c988b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize Country Code and Names across Dataset\n",
    "def standardize_country_code(df_orig):\n",
    "    '''\n",
    "    Standardizes post-2010 municipality codes to pre-2010 country codes\n",
    "    :param df_orig - A Pandas dataframe\n",
    "    :return a Pandas dataframe with the municipality code transformation applied\n",
    "\n",
    "    '''\n",
    "    df = df_orig.copy() #Create a copy of the dataframe\n",
    "    \n",
    "    #Iterate through dataframe and update municipality code and name\n",
    "    for row_idx in df.index:\n",
    "        code = df.at[row_idx, 'municipality_code']\n",
    "        new_code, name = geomap[code]\n",
    "        df.at[row_idx, 'municipality_code'] = new_code\n",
    "        df.at[row_idx, 'municipality_name'] = name\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b71046bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize Party Names (All Uppercase)\n",
    "def standardize_party_name(df):\n",
    "    '''\n",
    "    Standardizes political party names so that they are ALL CAPS\n",
    "    :param df - A Pandas dataframe\n",
    "    :return a Pandas dataframe with the municipality code transformation applied\n",
    "\n",
    "    '''\n",
    "    \n",
    "    #Remove Accents and make all Party names ALL CAPS\n",
    "    parties = df[\"party_name\"]\n",
    "    parties = [cleaning_utilities.remove_accents(party).upper() for party in parties]\n",
    "    df[\"party_name\"] = parties\n",
    "    \n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30d40a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to CSV\n",
    "def write_to_csv(df, path:str):\n",
    "    '''\n",
    "    Writes Cleaned Data Files to CSV\n",
    "    :param df - A Pandas dataframe\n",
    "    :param path - the location the CSV should be written to \n",
    "\n",
    "    '''\n",
    "    \n",
    "    df.to_csv(path_or_buf=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbad775",
   "metadata": {},
   "source": [
    "## Clean Electorate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9af5664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Files\n",
    "\n",
    "# obtain the data from csv\n",
    "df_1998 = extract_dataframe('../data/original/perfil_eleitorado_1998.csv', remove_extra_header=True)\n",
    "df_2002 = extract_dataframe('../data/original/perfil_eleitorado_2002.csv', remove_extra_header=True)\n",
    "df_2006 = extract_dataframe('../data/original/perfil_eleitorado_2006.csv', remove_extra_header=True)\n",
    "df_2010 = extract_dataframe('../data/original/perfil_eleitorado_2010.csv', remove_extra_header=False)\n",
    "df_2014 = extract_dataframe('../data/original/perfil_eleitorado_2014.csv', remove_extra_header=True)\n",
    "df_2018 = extract_dataframe('../data/original/perfil_eleitorado_2018.csv', remove_extra_header=True)\n",
    "\n",
    "#Standardize Country Codes\n",
    "df_2010 = standardize_country_code(df_2010)\n",
    "df_2014 = standardize_country_code(df_2014)\n",
    "df_2018 = standardize_country_code(df_2018)\n",
    "\n",
    "#Standardize Country Names\n",
    "df_1998 = standardize_country_name(df_1998)\n",
    "df_2002 = standardize_country_name(df_2002)\n",
    "df_2006 = standardize_country_name(df_2006)\n",
    "df_2010 = standardize_country_name(df_2010)\n",
    "df_2014 = standardize_country_name(df_2014)\n",
    "df_2018 = standardize_country_name(df_2018)\n",
    "\n",
    "#Standardize Educational Attainment Descriptions\n",
    "df_1998 = standardize_edu_attainment(df_1998)\n",
    "df_2002 = standardize_edu_attainment(df_2002)\n",
    "df_2006 = standardize_edu_attainment(df_2006)\n",
    "df_2010 = standardize_country_name(df_2010)\n",
    "df_2014 = standardize_country_name(df_2014)\n",
    "df_2018 = standardize_country_name(df_2018)\n",
    "\n",
    "\n",
    "# Adding educational attainment codes for 2010 and resolving the issue of 2018 accents\n",
    "clean2018(df_2018)\n",
    "df_2010 = add_education_codes(df_2002, df_2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fba0cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Clean Data To CSV\n",
    "write_to_csv(df_1998, path='../data/clean/perfil_eleitorado_1998.csv')\n",
    "write_to_csv(df_2002, path='../data/clean/perfil_eleitorado_2002.csv')\n",
    "write_to_csv(df_2006, path='../data/clean/perfil_eleitorado_2006.csv')\n",
    "write_to_csv(df_2010, path='../data/clean/perfil_eleitorado_2010.csv')\n",
    "write_to_csv(df_2014, path='../data/clean/perfil_eleitorado_2014.csv')\n",
    "write_to_csv(df_2018, path='../data/clean/perfil_eleitorado_2018.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195d824",
   "metadata": {},
   "source": [
    "## Clean Election Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2a371a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'educational_attainment_description'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'educational_attainment_description'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-45fad985a397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Extract DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_1998\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/original/1998_Election_Data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_extra_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_2002\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/original/2002_Election_Data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_extra_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_2006\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/original/2006_Election_Data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_extra_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_2010\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/original/2010_Election_Data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_extra_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-27efd12af0ee>\u001b[0m in \u001b[0;36mextract_dataframe\u001b[0;34m(path, remove_extra_header)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#Remove accents from educational attainment description\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0meducation_levels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"educational_attainment_description\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0meducation_levels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcleaning_utilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medu_desc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0medu_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meducation_levels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"educational_attainment_description\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meducation_levels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'educational_attainment_description'"
     ]
    }
   ],
   "source": [
    "#Extract DataFrames\n",
    "df_1998 = extract_dataframe('../data/original/1998_Election_Data.csv', remove_extra_header=True)\n",
    "df_2002 = extract_dataframe('../data/original/2002_Election_Data.csv', remove_extra_header=True)\n",
    "df_2006 = extract_dataframe('../data/original/2006_Election_Data.csv', remove_extra_header=True)\n",
    "df_2010 = extract_dataframe('../data/original/2010_Election_Data.csv', remove_extra_header=True)\n",
    "df_2014 = extract_dataframe('../data/original/2014_Election_Data.csv', remove_extra_header=True)\n",
    "df_2018 = extract_dataframe('../data/original/2018_Election_Data.csv', remove_extra_header=True)\n",
    "\n",
    "#Standardize Party Names\n",
    "df_1998 = standardize_party_name(df_1998)\n",
    "df_2002 = standardize_party_name(df_2002)\n",
    "df_2006 = standardize_party_name(df_2006)\n",
    "df_2010 = standardize_party_name(df_2010)\n",
    "df_2014 = standardize_party_name(df_2014)\n",
    "df_2018 = standardize_party_name(df_2018)\n",
    "\n",
    "#Standardize Country Codes\n",
    "df_2010 = standardize_country_code(df_2010)\n",
    "df_2014 = standardize_country_code(df_2014)\n",
    "df_2018 = standardize_country_code(df_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea14467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write Clean Data To CSV\n",
    "write_to_csv(df_1998, path='../data/clean/1998_Election_Data.csv')\n",
    "write_to_csv(df_2002, path='../data/clean/2002_Election_Data.csv')\n",
    "write_to_csv(df_2006, path='../data/clean/2006_Election_Data.csv')\n",
    "write_to_csv(df_2010, path='../data/clean/2010_Election_Data.csv')\n",
    "write_to_csv(df_2014, path='../data/clean/2014_Election_Data.csv')\n",
    "write_to_csv(df_2018, path='../data/clean/2018_Election_Data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
